{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmt_seq2seq1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnxJimgpSv7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "import re\n",
        "from pickle import dump\n",
        "from unicodedata import normalize\n",
        "from numpy import array\n",
        "from pickle import load\n",
        "import numpy as np\n",
        "from numpy.random import rand\n",
        "from numpy.random import shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJxY3f4sS1rQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical,plot_model\n",
        "from tensorflow.keras.losses import *\n",
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lrbjx9zCS3Np",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sizV5WfS6vp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "995e6470-5b89-4bbf-c509-e9f7dfa7cfd3"
      },
      "source": [
        "!wget http://www.manythings.org/anki/spa-eng.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-28 18:58:41--  http://www.manythings.org/anki/spa-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.109.196, 172.67.173.198, 104.24.108.196, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.109.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4781548 (4.6M) [application/zip]\n",
            "Saving to: ‘spa-eng.zip’\n",
            "\n",
            "\rspa-eng.zip           0%[                    ]       0  --.-KB/s               \rspa-eng.zip           9%[>                   ] 441.07K  1.91MB/s               \rspa-eng.zip         100%[===================>]   4.56M  12.4MB/s    in 0.4s    \n",
            "\n",
            "2020-06-28 18:58:41 (12.4 MB/s) - ‘spa-eng.zip’ saved [4781548/4781548]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2676LcuVS7Ui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6eb23fdd-0602-4786-9993-6c20b435f916"
      },
      "source": [
        "!unzip spa-eng.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  spa-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: spa.txt                 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHuotEgNS9S7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, mode='rt', encoding='utf-8')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "def to_pairs(doc):\n",
        "\tlines = doc.strip().split('\\n')\n",
        "\tpairs = [line.split('\\t')[:2] for line in  lines]\n",
        "\treturn pairs\n",
        "# clean a list of lines\n",
        "def clean_pairs(lines):\n",
        "\tcleaned = list()\n",
        "\t# prepare regex for char filtering\n",
        "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "\t# prepare translation table for removing punctuation\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\tfor pair in lines:\n",
        "\t\tclean_pair = list()\n",
        "\t\tfor line in pair:\n",
        "\t\t\t# normalize unicode characters\n",
        "\t\t\tline = normalize('NFD', line).encode('ascii', 'ignore')\n",
        "\t\t\tline = line.decode('UTF-8')\n",
        "\t\t\t# tokenize on white space\n",
        "\t\t\tline = line.split()\n",
        "\t\t\t# convert to lowercase\n",
        "\t\t\tline = [word.lower() for word in line]\n",
        "\t\t\t# remove punctuation from each token\n",
        "\t\t\tline = [word.translate(table) for word in line]\n",
        "\t\t\t# remove non-printable chars form each token\n",
        "\t\t\tline = [re_print.sub('', w) for w in line]\n",
        "\t\t\t# remove tokens with numbers in them\n",
        "\t\t\tline = [word for word in line if word.isalpha()]\n",
        "\t\t\t# store as string\n",
        "\t\t\tclean_pair.append(' '.join(line))\n",
        "\t\tcleaned.append(clean_pair)\n",
        "\treturn array(cleaned)\n",
        "def save_clean_data(sentences, filename):\n",
        "\tdump(sentences, open(filename, 'wb'))\n",
        "\tprint('Saved: %s' % filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZdc7KJCS_It",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "81c74c64-c1b1-45ce-9de4-68dba3c1af95"
      },
      "source": [
        "# load dataset\n",
        "filename = '/content/spa.txt'\n",
        "doc = load_doc(filename)\n",
        "# split into english-german pairs\n",
        "pairs = to_pairs(doc)\n",
        "# clean sentences\n",
        "clean_pairs = clean_pairs(pairs)\n",
        "# save clean pairs to file\n",
        "save_clean_data(clean_pairs, 'english-spanish.pkl')\n",
        "# spot check\n",
        "for i in range(10):\n",
        "\tprint('[%s] => [%s]' % (clean_pairs[i,0], clean_pairs[i,1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved: english-spanish.pkl\n",
            "[go] => [ve]\n",
            "[go] => [vete]\n",
            "[go] => [vaya]\n",
            "[go] => [vayase]\n",
            "[hi] => [hola]\n",
            "[run] => [corre]\n",
            "[run] => [corran]\n",
            "[run] => [corra]\n",
            "[run] => [corred]\n",
            "[run] => [corred]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhvYzpamTExe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "e20b1cef-e3e6-45c2-dcb2-b1f0a52a8493"
      },
      "source": [
        "for i in range(10):\n",
        "\tprint(clean_pairs[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['go' 've']\n",
            "['go' 'vete']\n",
            "['go' 'vaya']\n",
            "['go' 'vayase']\n",
            "['hi' 'hola']\n",
            "['run' 'corre']\n",
            "['run' 'corran']\n",
            "['run' 'corra']\n",
            "['run' 'corred']\n",
            "['run' 'corred']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACTZiCPbTG3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load a clean dataset\n",
        "def load_clean_sentences(filename):\n",
        "\treturn load(open(filename, 'rb'))\n",
        "\n",
        "# save a list of clean sentences to file\n",
        "def save_clean_data(sentences, filename):\n",
        "\tdump(sentences, open(filename, 'wb'))\n",
        "\tprint('Saved: %s' % filename)\n",
        "\n",
        "# fit a tokenizer\n",
        "def create_tokenizer(lines):\n",
        "\ttokenizer = Tokenizer()\n",
        "\ttokenizer.fit_on_texts(lines)\n",
        "\treturn tokenizer\n",
        "# max sentence length\n",
        "def max_length(lines):\n",
        "\treturn max(len(line.split()) for line in lines)\n",
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "\t# integer encode sequences\n",
        "\tX = tokenizer.texts_to_sequences(lines)\n",
        "\t# pad sequences with 0 values\n",
        "\tX = pad_sequences(X, maxlen=length, padding='post')\n",
        "\treturn X\n",
        "# one hot encode target sequence\n",
        "def encode_output(sequences, vocab_size):\n",
        "\tylist = list()\n",
        "\tfor sequence in sequences:\n",
        "\t\tencoded = to_categorical(sequence, num_classes=vocab_size)\n",
        "\t\tylist.append(encoded)\n",
        "\ty = array(ylist)\n",
        "\ty = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
        "\treturn y\n",
        "\n",
        "#EVALUATION FUNCTIONS\n",
        "# map an integer to a word\n",
        "def word_for_id(integer, tokenizer):\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == integer:\n",
        "\t\t\treturn word\n",
        "\treturn None\n",
        " \n",
        "# generate target given source sequence\n",
        "def predict_sequence(model, tokenizer, source):\n",
        "  predict = model.predict(source, verbose=0)[0]\n",
        "  integers = []\n",
        "  for pred in predict:\n",
        "    integers.append(np.argmax(pred))\n",
        "  target = []\n",
        "  for i in integers:\n",
        "    word = word_for_id(i, tokenizer)\n",
        "    if word is None:\n",
        "      break\n",
        "    target.append(word)\n",
        "  return ' '.join(target)\n",
        " \n",
        "# evaluate the skill of the model\n",
        "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
        "  actual = []\n",
        "  predicted = []\n",
        "  b1=0\n",
        "  b2=0\n",
        "  b3=0\n",
        "  b4=0\n",
        "  count = 0\n",
        "  for i, source in enumerate(sources):    # translate encoded source text\n",
        "    source = source.reshape((1, source.shape[0]))\n",
        "    translated = predict_sequence(model, tokenizer, source)\n",
        "    raw_src, raw_tgt = raw_dataset[i]\n",
        "    if i<10:\n",
        "      print('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_tgt, translated))\n",
        "      count = count+1\n",
        "    else:\n",
        "      break\n",
        "    actual.append([raw_tgt.split()])\n",
        "    predicted.append(translated.split())\n",
        "    b1=b1+ corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
        "    b2=b2+  corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
        "    b3=b3+ corpus_bleu(actual, predicted, weights=(0.33, 0.33, 0.33, 0))\n",
        "    b4=b4+ corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "  print(b1/count,b2/count,b3/count,b4/count)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeWLq9-nTIu9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "d14650c0-7a0e-4ae4-8225-33f8cd3d5fc2"
      },
      "source": [
        "# load dataset\n",
        "raw_dataset = load_clean_sentences('english-spanish.pkl')\n",
        "# reduce dataset size\n",
        "n_sentences = 100000\n",
        "dataset = raw_dataset[:n_sentences, :]\n",
        "remove_ind =[]\n",
        "\n",
        "# choosing max length of input and target\n",
        "en_length = 8\n",
        "es_length  =8\n",
        "for i in range(0,n_sentences):\n",
        "  a = dataset[i,0].split()[:en_length]\n",
        "  a = \" \".join(e for e in a)\n",
        "  dataset[i,0] = a\n",
        " \n",
        "  a = dataset[i,1].split()[:es_length]\n",
        "  a = \" \".join(e for e in a)\n",
        "  dataset[i,1] = a\n",
        "# random shuffle\n",
        "shuffle(dataset)\n",
        "# # split into train/test\n",
        "train, test = dataset[:49000], dataset[49000:]\n",
        "# save\n",
        "save_clean_data(dataset, 'english-spanish-both.pkl')\n",
        "save_clean_data(train, 'english-spanish-train.pkl')\n",
        "save_clean_data(test, 'english-spanish-test.pkl')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved: english-spanish-both.pkl\n",
            "Saved: english-spanish-train.pkl\n",
            "Saved: english-spanish-test.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PtEFyFsTc0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = load_clean_sentences('english-spanish-both.pkl')\n",
        "train = load_clean_sentences('english-spanish-train.pkl')\n",
        "test = load_clean_sentences('english-spanish-test.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJcv0w7yTgsY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "57579b52-402a-4636-d575-b136805ee997"
      },
      "source": [
        "dataset[56,0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'i dont follow'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7cPGOuLTiRw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "c8ee76bc-2701-49de-c2c3-9a7f6d2ec7cd"
      },
      "source": [
        "# prepare english tokenizer\n",
        "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "eng_length = max_length(dataset[:, 0])\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
        "print('English Max Length: %d' % (eng_length))\n",
        "# prepare german tokenizer\n",
        "es_tokenizer = create_tokenizer(dataset[:, 1])\n",
        "es_vocab_size = len(es_tokenizer.word_index) + 1\n",
        "es_length = max_length(dataset[:, 1])\n",
        "print('Spanish Vocabulary Size: %d' % es_vocab_size)\n",
        "print('Spanish Max Length: %d' % (es_length))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 10807\n",
            "English Max Length: 8\n",
            "Spanish Vocabulary Size: 20323\n",
            "Spanish Max Length: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P35yG8YLTj8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare training data\n",
        "trainX = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
        "trainY = encode_sequences(es_tokenizer, es_length, train[:, 1])\n",
        "#trainY = encode_output(trainY, es_vocab_size)\n",
        "# prepare validation data\n",
        "testX = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
        "testY = encode_sequences(es_tokenizer, es_length, test[:, 1])\n",
        "#testY = encode_output(testY, es_vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXt1N0tUTlnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as  tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yeCyJHGTnNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model= load_model('/content/drive/My Drive/Colab Notebooks/machine_translation_final.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIiSSGLvTwNn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "eb9be65c-a95f-4683-c158-a97358580c8d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 8)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_en (Embedding)        (None, 8, 100)       1080700     input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   [(None, 300), (None, 481200      embedding_en[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, 7)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 1, 300)       0           lstm_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "embedding_es (Embedding)        (None, 7, 300)       6096900     input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 8, 300)       0           reshape_3[0][0]                  \n",
            "                                                                 embedding_es[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   (None, 8, 300)       721200      concatenate_3[0][0]              \n",
            "                                                                 lstm_6[0][1]                     \n",
            "                                                                 lstm_6[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 8, 20323)     6117223     lstm_7[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 14,497,223\n",
            "Trainable params: 14,497,223\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7PGNNccT11S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################  MAIN MODEL CODE  ########################################3\n",
        "# def create_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units,dropout_rate):\n",
        "#   x_input1 = Input(shape=(src_timesteps,))\n",
        "#   x_input2 = Input(shape=(tar_timesteps-1,)) \n",
        "\n",
        "#   x=Embedding(input_dim=src_vocab,output_dim=100,embeddings_initializer=\"uniform\",name = \"embedding_en\")(x_input1)\n",
        "#   x1=Embedding(input_dim=tar_vocab,output_dim=300,embeddings_initializer=\"uniform\",name = \"embedding_es\")(x_input2)\n",
        "#   x_enc,state_h,state_c = LSTM(n_units,return_sequences=True,return_state = True,recurrent_dropout = dropout_rate)(x)\n",
        "#   enc_state = [state_h,state_c]\n",
        "\n",
        "\n",
        "#   x=Concatenate(axis=1)([x_enc,x1])\n",
        "#   x = LSTM(n_units,return_sequences=True,dropout=dropout_rate)(x)\n",
        "#   # # x = Bidirectional(LSTM(256,return_sequences=True))(x)\n",
        "#   # # x = LSTM(256,return_sequences=True,dropout=0.1)(x)\n",
        "#   x = Dense(tar_vocab,activation='softmax')(x)\n",
        "#   main_model = Model([x_input1,x_input2],x)\n",
        "\n",
        "#   return main_model\n",
        "\n",
        "# n_units = 300\n",
        "# dropout_rate = 0.3\n",
        "# model1 = create_model(eng_vocab_size, es_vocab_size, eng_length, es_length, n_units,dropout_rate)\n",
        "# model1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MufIJXR2Uzh1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad8060eb-49c3-4d49-bb16-3adbf2150f1f"
      },
      "source": [
        "trainX.shape , trainY.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((49000, 8), (49000, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrs4bXl5VFv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############### TO TRAIN THE MODEL  #######################################\n",
        "\n",
        "# %cd /content/\n",
        "# version = \"100_drop_0.2\"\n",
        "# filename = 'model'+str(n_units)+'_'+str(version)+'.h5'\n",
        "# checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "# los = SparseCategoricalCrossentropy()\n",
        "# opt = optimizers.Adam(lr=0.001)\n",
        "# opt1 = optimizers.RMSprop(0.5)\n",
        "# # model = load_model('model200_bi_100_drop_0.h5')\n",
        "# # model = leave_embed(model)\n",
        "# model.compile(loss=los,optimizer=opt,metrics=['accuracy'])\n",
        "\n",
        "# model.fit([trainX,trainY[:,0:en_length-1]], trainY, epochs=50, batch_size=256, validation_data=([testX,testY[:,0:en_length-1]], testY), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pV8qF5_VdKo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "95fbcaaa-4f94-49dd-cb95-3fb5245ab407"
      },
      "source": [
        "sam=20\n",
        "for j in range(0,40,5):\n",
        "  sam=sam+j\n",
        "  x_input11=testX[sam].reshape(1,en_length)\n",
        "  x_input21=np.zeros((1,en_length-1)) \n",
        "  for i in range(0,en_length-1):\n",
        "    output = model.predict([x_input11,x_input21])\n",
        "    out1=np.argmax(output,axis=2)\n",
        "    a = out1[0,i]\n",
        "    if i !=7:\n",
        "      x_input21[0,i]=a\n",
        "  prediction = x_input21[0].tolist()\n",
        "  prediction.append(a)\n",
        "  print('\\n')\n",
        "  print(\" predicted spanish:  \",end=\"\")\n",
        "  for w in prediction:\n",
        "    try:\n",
        "      print(es_tokenizer.index_word[w],end=\" \")\n",
        "    except:\n",
        "      print(\"-\",end=\" \")\n",
        "  print('\\n'+\" actual spanish:  \",end=\"\")\n",
        "  for i in testY[sam]:\n",
        "    try:\n",
        "      print(es_tokenizer.index_word[i],end=\" \")\n",
        "    except: \n",
        "      print(\"-\",end=\" \")\n",
        "\n",
        "  print('\\n'+\" actual english:  \",end=\"\")\n",
        "  for i in testX[sam]:\n",
        "    try:\n",
        "      print(eng_tokenizer.index_word[i],end=\" \")\n",
        "    except: \n",
        "      print(\"-\",end=\" \")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            " predicted spanish:  el la ensenarias - - - - - \n",
            " actual spanish:  el salio de la habitacion - - - \n",
            " actual english:  he left the room - - - - \n",
            "\n",
            " predicted spanish:  el profesor se saltar al amamos - - \n",
            " actual spanish:  el asesino confeso su crimen - - - \n",
            " actual english:  the murderer confessed his crime - - - \n",
            "\n",
            " predicted spanish:  ella se fue de la habil en en \n",
            " actual spanish:  ella fallecio tranquilamente mientras dormia - - - \n",
            " actual english:  she passed away peacefully in her sleep - \n",
            "\n",
            " predicted spanish:  yo estaba tan amistad - - - - \n",
            " actual spanish:  me estaba duchando hace un momento - - \n",
            " actual english:  i was showering a moment ago - - \n",
            "\n",
            " predicted spanish:  tu verdad lo que te gusta hacer hacer \n",
            " actual spanish:  se supone que teneis que hacerlo vosotras - \n",
            " actual english:  youre supposed to do that yourselves - - \n",
            "\n",
            " predicted spanish:  verdad el mensaje del gran - - - \n",
            " actual spanish:  eres la peor mentirosa del mundo - - \n",
            " actual english:  youre the worst liar in the world - \n",
            "\n",
            " predicted spanish:  por favor nos lo absoluto - - - \n",
            " actual spanish:  contamos con ustedes - - - - - \n",
            " actual english:  we count on you - - - - \n",
            "\n",
            " predicted spanish:  me cuanto debo adondequiera - - - - \n",
            " actual spanish:  me moriria antes de casarme con el - \n",
            " actual english:  i would rather die than marry him - "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT58V67_Vd0n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "4ff76c29-748b-4d68-a3fd-321078c273cc"
      },
      "source": [
        "sam = 0\n",
        "b1=0\n",
        "b2=0\n",
        "b3=0\n",
        "b4=0\n",
        "\n",
        "min_b1=2\n",
        "min_b2=2\n",
        "min_b3=2\n",
        "min_b4=2\n",
        "\n",
        "count = 0\n",
        "check=0\n",
        "for j in range(0,100):\n",
        "  count = count+1\n",
        "  sam =sam +20\n",
        "  actual=[]\n",
        "  predicted =[]\n",
        "\n",
        "\n",
        "  x_input11=testX[sam].reshape(1,en_length)\n",
        "  x_input21=np.zeros((1,en_length-1)) \n",
        "  for i in range(0,en_length-1):\n",
        "    output = model.predict([x_input11,x_input21])\n",
        "    out1=np.argmax(output,axis=2)\n",
        "    a = out1[0,i]\n",
        "    if i !=7:\n",
        "      x_input21[0,i]=a\n",
        "  prediction = x_input21[0].tolist()\n",
        "  prediction.append(a)\n",
        "\n",
        "\n",
        "  # print(\" predicted spanish:  \",end=\"\")\n",
        "  for w in prediction:\n",
        "    try:\n",
        "      # print(es_tokenizer.index_word[w],end=\" \")\n",
        "      predicted.append(es_tokenizer.index_word[w])\n",
        "    except:\n",
        "      predicted.append('-')\n",
        "      #  print(\"-\",end=\" \")\n",
        "  # print('\\n'+\" actual spanish:  \",end=\"\")\n",
        "  for i in testY[sam]:\n",
        "    try:\n",
        "      # print(es_tokenizer.index_word[i],end=\" \")\n",
        "      actual.append(es_tokenizer.index_word[i])\n",
        "    except: \n",
        "      actual.append('-')\n",
        "      # print(\"-\",end=\" \")\n",
        "\n",
        "  # print('\\n'+\" actual english:  \",end=\"\")\n",
        "  # for i in testX[sam]:\n",
        "  #   try:\n",
        "  #     # print(eng_tokenizer.index_word[i],end=\" \")\n",
        "  #   except: \n",
        "  #     pass\n",
        "  #     # print(\"-\",end=\" \")\n",
        "  try:\n",
        "    che = corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0))\n",
        "    if (che<min_b1):\n",
        "      min_b1 =che\n",
        "    b1=b1+ che\n",
        "\n",
        "    che = corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0))\n",
        "    if (che<min_b2):\n",
        "      min_b2 =che\n",
        "    b2=b2+ che\n",
        "\n",
        "    che = corpus_bleu(actual, predicted, weights=(0.33, 0.33, 0.33, 0))\n",
        "    if (che<min_b3):\n",
        "      min_b3 =che\n",
        "    b3=b3+ che\n",
        "\n",
        "\n",
        "    che = corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25))\n",
        "    if (che<min_b4):\n",
        "      min_b4 =che\n",
        "    b4=b4+ che\n",
        "\n",
        "    check= check+1\n",
        "  except:\n",
        "    pass\n",
        "print(\"BLEU Score:  \")\n",
        "print(b1/check,b2/check,b3/check,b4/check)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU Score:  \n",
            "0.45008423882295484 0.6479264710386536 0.7444514531535646 0.7970899281491551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TsOcNTrVo20",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "625ebc3c-925c-437e-a09a-65f98bb6af65"
      },
      "source": [
        "print(\"Minimum BLEU score:  \")\n",
        "print(min_b1,min_b2,min_b3,min_b4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum BLEU score:  \n",
            "0.047619047619047616 0.2182178902359924 0.3661572458236839 0.4671379777282001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NspIGyHXWDHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}